#+HUGO_BASE_DIR: ../
#+EXPORT_DATE:
#+OPTIONS:  ^:nil
#+HUGO_SECTION: post/
#+HUGO_AUTO_SET_LASTMOD: t
#+DATE: 2012-07-15

* Programming                                                  :@programming:

** DONE Bokeh plot in Django and with REST and Flask :python:flask:django:bokeh:
   CLOSED: [2017-12-19 Tue 17:53]
   :PROPERTIES:
   :EXPORT_FILE_NAME: rest_bokeh
   :END:

Last weeks I have working with a django app for research. I will update it when
it will be ready ;-).

However, the introduction of Javascript and specifically [[https://vuejs.org/][Vue.js]] have produce
that the website is mainly dynamic using JS and not Python. Also, we have done
a static website [[http://www.tflsgo.org/]] (using [[https://docs.gitlab.com/ee/user/project/pages/index.html][Gitlab Page]] and [[https://jekyllrb.com/][Jekyll]]), so I
started considering to transform the website to a static website using Rest
service with Python.

First, I was considering [[http://www.django-rest-framework.org/][Django Rest Framework]] but finally I decided to use
[[https://flask-restful.readthedocs.io/en/latest/][Flask-Restful]] by its simplicity (and [[http://flask-sqlalchemy.pocoo.org/2.3/][Flask-SQLAlchemy]] for the communication with
the database).

The problem with that was how to serve the [[https://bokeh.pydata.org/en/latest/][Bokeh]] figures as Rest services. I
starting reading websites and manual and searching but I didn't get any
satisfactory answer.

Hours later, I obtained the answer, so I am going to explain it to avoid the reader
to waste his/her time.

*** Using django

First,  the solution is the embed subpackage at
https://bokeh.pydata.org/en/latest/docs/reference/embed.html.  There are several
options:

-  file_html :: generate the html output, it is not useful for  rest.

- server_document :: It requires a Bokeh server.

- components :: It returns a js script and a div to include.

- autoload_static :: It returns a js function and a div to include.

In the django layout, I used:

#+BEGIN_SRC html
<html>
<head>
...
{% block bokeh_js %}{% endblock %}
</head>
<body>
...
{% block bokeh_fig %}{% endblock %}
</body>
</body>
#+END_SRC

In the template I done:

#+BEGIN_SRC html
{% block bokeh_fig %}
{% for fig in bokeh_divs %}
<h2>{{fig.0}}</h2>
{{ fig.1 | safe}}
{% endfor %}
{% endblock %}
#+END_SRC

*safe* is required to allow the bokeh visualization,  and *fig* is a dictionary.
Using the default django template system,  *fig.0* refers to the key and *fig.1*
refers to the value.

When the views generate these variable by:

#+BEGIN_SRC python
    scripts, divs = components(figs)

    return render(request, 'compare.html', {
       # ...
       'bokeh_script':  scripts,
       'bokeh_divs':  divs_sorted,
    })
#+END_SRC

when figs is a dictionary with the different plot by figures. The idea was to
visualize the plots with a title with the caption of each one of them.

***  Flask-Rest version

Although we could visualize using function *components*, for the Rest service it
was not adequate.

In the html page, the bokeh and jquery are required:

#+BEGIN_SRC html
<script src="https://code.jquery.com/jquery-3.2.1.min.js"></script>
<script src="http://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.js"></script>
<script src="http://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.js"></script>
<script src="http://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.js"></script>
#+END_SRC

and a div in which the figure will be shown:

#+BEGIN_SRC html
<body>
...
<div id="#fig"></div>
</body>
#+END_SRC

The complete file is:

#+BEGIN_SRC html
<!doctype html>
<html>
    <head>
        <title>Test</title>
<script src="https://code.jquery.com/jquery-3.2.1.min.js"></script>
<script src="http://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.js"></script>
<script src="http://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.js"></script>
<script src="http://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.js"></script>
        <meta charset="utf-8" />
    </head>
    <body>
        <h1>Test</h1>
        <div id="fig"></div>
        <script src="./run.js"></script>
    </body>
</html>
#+END_SRC



Then, the web apps include:

#+BEGIN_SRC python
from flask import Flask
from flask_restful import Resource, Api
from flask_cors import CORS

from holoviews as hv
from bokeh.resources import CDN
from bokeh.embed import autoload_static

# Create the app
app = Flask(__name__)
# Initially I was the error Cross Origin Resource Sharing
# that allow all origin domains, not complete sure, only by demo
CORS(app)
# Restful
api = Api(app)

# Configurate  holoviews to create bokeh figures
hv.extension('bokeh')
renderer = hv.renderer('bokeh')

# An example of generation of bokeh
def get_plot():
    xs = range(-10,11)
    ys = [100+x**2 for x in xs]
    plot_hv = hv.Curve((xs, ys))
    plot = renderer.get_plot(plot_hv).state
    return plot

# Example
class Figure(Resource):
    def get(self):
        plot = get_plot()
        div, js = components(plot)
        js, tags = autoload_static(plot, CDN, "fig/")
       return {'js': js, 'tags': tags}

api.add_resource(Figure, '/fig')

if __name__ == '__main__':
    app.run()
#+END_SRC

The js variable is the javascript function to run the visualization of the Bokeh
figure, and tags is the div in which the figure will be shown.

The final JS code is:

#+BEGIN_SRC javascript
        $.ajax({
            url: 'http://localhost:5000/fig',
            method: 'GET',
            success: function(data) {
                console.log(data);
                // First,  the div code is inserted
                $('#fig').replaceWith(data['tags']);
                // Later, the JS code must be evaluated
                eval(data['js']);
            },
        });
#+END_SRC

And the result is:

[[file:/img/rest_test.png]]

** DONE Improving performance in Python                  :python:performance:
   CLOSED: [2017-12-19 Tue 17:53]
   :PROPERTIES:
   :EXPORT_FILE_NAME: improving_python1
   :EXPORT_DATE: 2012-07-15
   :END:

All the source code of this post is available at [[https://github.com/dmolina/pyreal][github]].

In the previous post, I recognized my predilection for Python. For me, it is a great language for create prototypes in
many areas. For my research work, I usually creates/designs algorithms for continuous optimization using
[[http://en.wikipedia.org/wiki/Evolutionary_algorithm][evolutionary algorithms]]. For these algorithms, languages like C/C++ or Java are widely used, specially for its
good performance (to publish, it is usual to have to make many comparisons between algorithms, so the performance
could be critical. However, for testing new ideas, many authors uses other tools like Mathlab that reduces the
developer time at the cost of a higher computing time.

I agree that Mathlab is great for numerical algorithms, but I still prefer Python over Mathlab, because I'm more confortable
with it, and have many libraries, and it's more simpler to call code in other languages, written in C or Java. That allow us
to increase the performance, and I like to test how much it could be improved.

Several months ago, I start writing my most succesful algorithm, [[http://sci2s.ugr.es/EAMHCO/#macmals][Memetic Algorithms based on LS Chaining]], in Python. I had several
doubts about the performance, so I start writing one element, an Steady-State Genetic Algorithm, in Python.

*** Calling C/C++ code from python

  The first challenge I had to tackle was to allow my python program to use the same benchmark functions than other implementations,
  [[http://sci2s.ugr.es/EAMHCO/#TestF][CEC'2005 benchmark]].
  This benchmark define the functions to optimize, thus its main funtionality is
  evaluate my solutions, when each solution is a vector of real numbers, with a real fitness value.
  The benchmark code was implemented (by its authors) in C/C++. So, my python code have to call C++ code.

  For doing that, I used the library [[http://www.boost.org/doc/libs/1_50_0/libs/python/doc/index.html][boost::python]], that is, in my opinion, the simpler way to call C/C++ code, specially
  when we uses [[http://numpy.scipy.org/][numpy]] package.

  In my case, it is very simple, because I need few functions:

  #+begin_src python
    #include <boost/python.hpp>
    #include <boost/python/numeric.hpp>
    #include <boost/python/list.hpp>
    #include <iostream>
    #include "cec2005/cec2005.h"
    #include "cec2005/srandom.h"

    using namespace boost::python;

    Random r(new SRandom(12345679));

    void set_function(int fun, int dim) {
        init_cec2005(&r, fun, dim);
    }

    double evalua(const numeric::array &el) {
       const tuple &shape = extract<tuple>(el.attr("shape"));
       unsigned n = boost::python::extract<unsigned>(shape[0]);
       double *tmp = new double[n];
      for(unsigned int i = 0; i < n; i++)
        {
          tmp[i] = boost::python::extract<double>(el[i]);
        }
      double result = eval_cec2005(tmp, n);
      delete tmp;
      return result;
    }
    ...

    BOOST_PYTHON_MODULE(libpycec2005)
    {
        using namespace boost::python;
        numeric::array::set_module_and_type( "numpy", "ndarray");
        def("config", &set_function);
        def("evaluate", &evalua);
        ...
    }
  #+end_src

  More info in the good [[http://www.boost.org/doc/libs/1_50_0/libs/python/doc/index.html][boost::python]] documentation.

  One we can call C/C++ code, we have implemented the algorithm in python code.
  The test code was the following:

  #+begin_src python
    from ssga import SSGA
    from readargs import ArgsCEC05
    import libpycec2005 as cec2005
    import numpy

    def check_dimension(option, opt, value):
        if value not in [2, 10, 30, 50]:
            raise OptionValueError(
                "option %s: invalid dimensionality value: %r" % (opt, value))

    def main():
        """
        Main program
        """
        args = ArgsCEC05()

        if  args.hasError:
            args.print_help_exit()

        fun = args.function
        dim = args.dimension

        print "Function: %d" %fun
        print "Dimension: %d" %dim
        cec2005.config(fun, dim)
        domain = cec2005.domain(fun)
        print "Domain: ", domain
        ea = SSGA(domain=domain, size=60, dim=dim, fitness=cec2005.evaluate)

        for x in xrange(25):
            ea.run(maxeval=dim*10000)
            [bestsol, bestfit] = ea.getBest()
            print "BestSol: ", bestsol
            print "BestFitness: %e" %bestfit
            ea.reset()

    if __name__ == "__main__":
        main()
  #+end_src

  This source code run the algorithm 25 times, and in each run the algorithm stops when they are created 10000*dim solutions.
  These conditions are indicated in the [[http://sci2s.ugr.es/EAMHCO/Tech-Report-May-30-05.pdf][benchmark specification]]. The only parameter was the function (-f, used function 1 by
  default) and dimension (-d) from 10, 30, 50.

*** Profiling the computing time

  How much time it takes? I have changed xrange(25) for xrange(1) and we have run its current version.
  The final time was 7 minutes for dimension 10, and 21 minutes for dimension 30 (for only one function).

  Because I like to make more interesting things,  that only waiting computing time, I use the profile, only
  one run for the function, to detect the functions/method more expensive in computing time.

  #+begin_src bash
  python -m cProfile runcec.py -f 1 -d 10
  #+end_src

  The output was the following:

  #+begin_src bash
          2943600 function calls (2943531 primitive calls) in 31.031 seconds

     Ordered by: standard name

     ncalls  tottime  percall  cumtime  percall filename:lineno(function)
  ....
        1    0.001    0.001    0.126    0.126 ssga.py:1(<module>)
      99940    0.561    0.000   17.463    0.000 ssga.py:109(cross)
          1    0.000    0.000    0.000    0.000 ssga.py:123(reset)
          1    5.559    5.559   51.129   51.129 ssga.py:126(run)
          1    0.000    0.000    0.000    0.000 ssga.py:14(__init__)
          1    0.000    0.000    0.000    0.000 ssga.py:158(getBest)
          1    0.000    0.000    0.000    0.000 ssga.py:31(set_mutation_rate)
      99940    0.730    0.000    1.885    0.000 ssga.py:45(mutation)
      12438    0.286    0.000    0.758    0.000 ssga.py:50(mutationBGA)
          1    0.002    0.002    0.002    0.002 ssga.py:77(initPopulation)
     105883    1.101    0.000    5.604    0.000 ssga.py:89(updateWorst)
          1    0.000    0.000    0.000    0.000 ssga.py:9(SSGA)
      99940    1.049    0.000   20.617    0.000 ssga.py:97(getParents)
  ...

  #+end_src

  With the profile we can observe the most expensive methods in our code:
  getParents (20 seconds), crossover operator (17 seconds), and updateWorst (5 seconds).
  These methods are the 85% of the computing time, and the first two methods the 74%
  of the computing time.


*** Optimising the code

  That proves the majority of computing time is due to a minority of the code,
  only three methods. If we can optimize these methods, our code could be
  improved a lot.

  We can uses again the [[http://www.boost.org/doc/libs/1_50_0/libs/python/doc/index.html][boost::python]] package, but it's a bit tedious to use it. So, we have
  used the [[http://www.cython.org/][cython]] package. With cython we can optimize the source code adding
  information about the types.

  For instead, Instead of the following code:

  #+begin_src python
    import numpy as np

    def distance(ind1,ind2):
        """
        Euclidean distance
        ind1 -- first array to compare
        ind2 -- second array to compare

        Return euclidean distance between the individuals

        >>> from numpy.random import rand
        >>> import numpy as np
        >>> dim = 30
        >>> sol = rand(dim)
        >>> distance(sol,sol)
        0.0
        >>> ref=np.zeros(dim)
        >>> dist=distance(sol,ref)
        >>> dist > 0
        True
        >>> dist2 = distance(sol*2,ref)
        >>> 2*dist == dist2
        True
        """
        dif = ind1-ind2
        sum = (dif*dif).sum()
        return math.sqrt(sum)
  #+end_src

  we can write:

  #+begin_src python
    cimport numpy as np
    cimport cython
    DTYPE = np.double
    ctypedef np.double_t DTYPE_t
    ctypedef np.int_t BTYPE_t

    def distance(np.ndarray[DTYPE_t, ndim=1]ind1, np.ndarray[DTYPE_t, ndim=1] ind2):
        """
        Euclidean distance
        ind1 -- first array to compare
        ind2 -- second array to compare

        ....
        """
        cdef np.ndarray[DTYPE_t, ndim=1] dif = ind1-ind2
        cdef double sum = (dif*dif).sum()
        return math.sqrt(sum)
  #+end_src

  We can see that is still very readable. we only have put information about the type
  and dimension in the vector parameters and about the variables, using the keyword
  cdef.

  Let's see as an example the first method, the crossover operator, implemented
  in the crossBLX method:

  #+begin_src python
    import numpy as np
    import math

    def crossBLX(mother,parent,domain,alpha):
        """
        crossover operator BLX-alpha

        mother -- mother (first individual)
        parent -- parent (second individual)
        domain -- domain to check
        alpha  -- parameter alpha

        Returns the new children following the expression children = random(x-alpha*dif, y+alpha*dif),
                    where dif=abs(x,y) and x=lower(mother,parents), y=upper(mother,parents)

        >>> import numpy as np
        >>> low=-5
        >>> upper = 5
        >>> dim=30
        >>> sol = np.array([1,2,3,2,1])
        >>> crossBLX(sol,sol,[low,upper],0)
        array([ 1.,  2.,  3.,  2.,  1.])
        """
        diff = abs(mother-parent)
        dim = mother.size
        I=diff*alpha
        points = np.array([mother,parent])
        A=np.amin(points,axis=0)-I
        B=np.amax(points,axis=0)+I
        children = np.random.uniform(A,B,dim)
        [low,high]=domain
        return np.clip(children, low, high)

  #+end_src

  We can see that it is very simple to implement using numpy, but it is still very slow. With cython I have
  defined directly implement the many operations, the following code:

  #+begin_src python
    def crossBLX(np.ndarray[DTYPE_t, ndim=1] mother,np.ndarray[DTYPE_t, ndim=1] parent,list domain, double alpha):
        """
        ...
        """
        cdef np.ndarray[DTYPE_t, ndim=1] C, r
        cdef int low, high, dim
        cdef double x, y
        cdef double I, A, B
        cdef unsigned i
        [low,high]=domain
        dim = mother.shape[0]
        C = np.zeros(dim)
        r = random.randreal(0,1,dim)

        for i in range(dim):
            if mother[i] < parent[i]:
               (x,y) = (mother[i],parent[i])
            else:
               (y,x) = (mother[i],parent[i])

            I = alpha*(y-x)
            A=x-I
            B=y+I

            if (A < low):
                A = low
            if (B > high):
                B = high

            C[i] = A+r[i]*(B-A)

        return C

  #+end_src

  It's true that the source code is more complicated, but it is still very readable.
  I have compared the two implementation to make sure both return the same values.

*** Measuring the improvement

  How much these small changes in the code?
  I have profile the source code again and it gives me:

  #+begin_src bash
           1020045 function calls (1019976 primitive calls) in 18.003 seconds

     Ordered by: standard name

     ncalls  tottime  percall  cumtime  percall filename:lineno(function)
  ....
          1    0.001    0.001    0.127    0.127 ssga.py:1(<module>)
      99940    0.425    0.000    2.432    0.000 ssga.py:109(cross)
          1    0.000    0.000    0.000    0.000 ssga.py:123(reset)
          1    5.415    5.415   17.864   17.864 ssga.py:126(run)
          1    0.000    0.000    0.000    0.000 ssga.py:14(__init__)
          1    0.000    0.000    0.000    0.000 ssga.py:158(getBest)
          1    0.000    0.000    0.000    0.000 ssga.py:31(set_mutation_rate)
      99940    0.699    0.000    2.006    0.000 ssga.py:45(mutation)
      12544    0.338    0.000    0.929    0.000 ssga.py:50(mutationBGA)
          1    0.002    0.002    0.002    0.002 ssga.py:77(initPopulation)
     105959    0.775    0.000    1.343    0.000 ssga.py:89(updateWorst)
          1    0.000    0.000    0.000    0.000 ssga.py:9(SSGA)
      99940    0.940    0.000    6.665    0.000 ssga.py:97(getParents)
  ....

  #+end_src

  We can see the improvement obtained.

  |------------------+--------+--------|
  | Method           | Python | Cython |
  |------------------+--------+--------|
  | cross          : |   17.4 |    2.4 |
  | getParents     : |   20.6 |    6.6 |
  | updateWorst    : |    5.6 |    1.3 |
  |------------------+--------+--------|
  | Total            |   43.6 |   10.3 |
  |------------------+--------+--------|


  The new code takes only a 23% of the computing time of the previous code.
  With these changes, we have reduced the total time from 51 seconds to 18 code.

*** In perspective

  Now, I run the source code without the profile, and test the source code obtaining the
  following time:

  |-------------+--------+-------------+--------|
  | Method      | dim=10 | dim=30      | dim=50 |
  |-------------+--------+-------------+--------|
  | Python      | 44s    | 3240s (54m) | --     |
  | Cython      | 10s    | 28s         | 48s    |
  |-------------+--------+-------------+--------|
  | Improvement | 77%    | 99%         | ---    |
  |-------------+--------+-------------+--------|

  In the following table, we test the maximum time for one and 25 runs (the time depends on the
  function used).

  |------------+---------+---------+--------|
  | #functions | dim=10  | dim=30  | dim=50 |
  |------------+---------+---------+--------|
  |          1 | 10s/18s | 28s/40s | 48s/1m |
  |         25 | 3/7m    | 15/21m  | 38m/   |
  |------------+---------+---------+--------|

  So, the total computing time is 7 minutes for dimension 10, and 21 minutes for dimension 30.
  These numbers are very acceptable, specially because we can test in parallel the different functions
  in a cluster of computers. Unfortunately, an implementation in Mathlab not only take more time, but
  also, for licensing reasons, it could not run in parallel without limit.

  In resume, we can uses python code, not only to create experimental prototypes, but also to create
  functional prototypes.

  And about the possible testing problem, I've been working on it, but I think it is enough for a post,
  didn't it? :-)

  All the code refered in the post, both in python and cython, is available at [[https://github.com/dmolina/pyreal][github]], if you want to see it.

**** Fuente de la Tabla 1                                          :noexport:
  |------------------+--------+--------|
  | Method           | Python | Cython |
  |------------------+--------+--------|
  | cross          : |   17.4 |    2.4 |
  | getParents     : |   20.6 |    6.6 |
  | updateWorst    : |    5.6 |    1.3 |
  |------------------+--------+--------|
  | Total            |   43.6 |   10.3 |
  | ^                |    sum |    sum |
  |------------------+--------+--------|
  #+TBLFM: $sum=vsum(@2..@-1)

​* Footnotes
​* COMMENT Local Variables                                           :ARCHIVE:
# Local Variables:
# eval: (add-hook 'after-save-hook #'org-hugo-export-subtree-to-md-after-save :append :local)
# End:


** DONE Callback that stop algorithm in R                            :R:util:
   CLOSED: [2017-12-19 Tue 17:53]
   :PROPERTIES:
   :EXPORT_FILE_NAME: rmain
   :EXPORT_DATE: 2012-07-10
   :END:

Today I was making a little programming using the mathematical software R (very useful
 for statistics, by the way), for a little test.

I'm one of the authors of a Cran package ([[http://cran.r-project.org/web/packages/Rmalschains/index.html][Rmalschains]]) for continuous optimization, and I was testing another packages to compare results.

Comparing a particular package I realise that the API doesn't give me enough control for
the comparisons. Briefly, to compare different algorithms all of them should stop when the same
number of solutions is achieved. Unfortunately, for the DE package, the stopping criterion is the
maximum iterations number, and for one strategy (the default strategy) this number differs,
maintaining the same maximum iterations number, in function of the function to improve. I know, not
so briefly :-).

In resume, I want to pass a function to evaluate solutions to an algorithm, and that only the first
/maxEvals/ solutions could be considered. So, it should be nice that after /maxEvals/ function evaluations
the algorithm will stop.

The aim is very simple in a theorical way, but I have only the control over a callback function used by
the algorithm, and I cannot use an 'exit' function into the function, because in that case will stop the global program,
not only the current state of the algorithm.

The solution? Using these 'complex' concepts that many people think that are useless, specially my CS students :-).
Combining a call with continuation with a closure:

#+begin_src R
finalFitness = callCC (function(exitFitness) {
     fitnessCheck <- function(fn, maxevals) {
          function(x) {

               if (total == 0 || total < maxevals) {
                  total <<- total +1;
                  fitness = fn(x);

                  if (total == 1 || fitness < bestFitness) {
                     bestFitness <<- fitness;
                  }

               }

               if (total >= maxevals) {
                  exitFitness(bestFitness);
               }


               fitness;
           }

      }


      fitCheck = fitnessCheck(fun$fitness, fun$maxevals)

      log <- capture.output({
          total <- 0
          result=DEoptim(fitCheck, lower, upper, control=list(itermax=fun$maxevals/NP))
      })

      exitFitness(result$optim$bestval)
})
#+end_src

I know, it is a bit confusing. callCC implement the concept of /call-with-current-continuation/
to run a code with an /exit/ function *exitFitness* that allows me to stop the run of the algorithm.
Because the function only does a run of the  algorithm (*DEOptim*), I can stop when I want.
Also, to make it more elegant, I use a closure *fitnessCheck*  that receives a function and a
maximum number of call, and it stops when the maximum calls number is achieved
(/total/ and /bestFitness/ are global variable, so the way to modify their values is using
<<- instead of the classical <- or =).

By the way, *capture.output* is a function that disables all the output of DEoptim algorithm.




** DONE Property-Based Testing                               :python:testing:
   CLOSED: [2017-12-19 Tue 17:52]
   :PROPERTIES:
   :EXPORT_FILE_NAME: hypothesis_test
   :EXPORT_DATE: 2017-10-24
   :END:

Today I was reviewing a paper that I am doing in collaboration with other colleagues,
a Phd student living in Sweden (in Västerås, a lovely city at a hour from Stockholm,
I had a stay for 3 months three years ago). Then, to be sure that the proposed algorithm,
a memetic version of a Differential Evolution, I started to implement it.

During the code, I need to create group of random variables, without repetition.

it could be generated in the following way:

#+BEGIN_SRC python
for i in range(popsize):
    r1[i] = np.random.rand...
    r2[i] = np.random.rand...

    while r1[i] == r2[i]:
        r2[i] = np.random.rand...
#+END_SRC

However, it is not practical, for Matlab/Numpy it is better to work as vectors:

#+BEGIN_SRC python
r1 = np.random.choice(popsize, popsize)
r2 = np.random.choice(popsize, popsize)
# Avoid repeated values
r2 = change_repeated(r2, r1, popsize)
#+END_SRC

I need *change_repeated* to randomly generated again the values in r2 when it is equals
than r1 (in the same position).

Then, I create the function:

#+BEGIN_SRC python
def change_repeated(values, original, maxvalue: int):
    """
    Repeat the values which are equals than original (position by position)

    :param values: array vector
    :param original: array vector or elements to not repeat
    :param maxvalue: maximum value (new ones will be between [0,  maxvalue])
    :returns: list of new values
    :rtype: ndarray.

    """
    equals, = np.nonzero(values == original)

    while len(equals) > 0:
        size = len(equals)
        values[equals] = np.random.choice(maxvalue, size)
        equals, = np.nonzero(values == original)

    return values
#+END_SRC

Great! Now, how I could test it? It could give several examples, and test again them. However,
this type of tests can be very boring, so I applied [[https://es.slideshare.net/ScottWlaschin/an-introduction-to-property-based-testing][Property-based testing]].

In this type of tests, instead of comparing examples of inputs and outputs, you test properties
that the function should follow for every possible input.

For instance, if you have implemented sqrt function:

- Traditional testing :: Check sqrt(25)==5,  sqrt(16)==4,  sqrt(9)==3,  sqrt(5)=2.23....

- Property-based testing :: Check that the result of sqrt multiply for itself gives the original number.

#+BEGIN_EXPORT latex
sqrt(num)^2 == num,  \forall num \in \Real
sqrt(num) >= 0
#+END_EXPORT

When you are using property-based testing, you can use a particular library to
automatically run your test with random inputs (with some constraints) hundreds
of times.
There are many tools for this: from the original [[https://en.wikipedia.org/wiki/QuickCheck][QuickCheck]], [[https://www.scalacheck.org/][ScalaCheck]] for Scala, or [[https://github.com/HypothesisWorks/hypothesis-python][Hypothesis]] for Python.
In our case,  we are using the simple Hypothesis, that it is very [[https://hypothesis.readthedocs.io/en/latest/quickstart.html][well-documented]].

In our case, the properties of repeated(ys, xs) are:

- when xs and ys have some variable in common:

  + repeated(ys,  xs) must be different than ys.

  + the result must be different than original vector (to avoid to modify the original one).

  + The indexes where ys and repeated(ys, xs) are different xs == ys.

The testing was done in the following way:

First the import:

#+BEGIN_SRC python
from hypothesis import given
import hypothesis.strategies as st
import numpy as np
#+END_SRC

- Then, we describe the range of float values:

#+BEGIN_SRC python
type_index = st.integers(min_value=0, max_value=popsize)
#+END_SRC

In that way, type_index create random values between [0,  popsize-1]

Then, we define the input as a list of previous integers:

#+BEGIN_SRC python
type_list = st.lists(type_index, min_size=popsize, max_size=popsize)
#+END_SRC

We have set the min_size and max_size equals to get lists with the same size.
Hypothesis works by default with lists of different sizes.

Then, we say the type of each parameter:

#+BEGIN_SRC python
@given(type_list, type_list)
def test_random_norepeat(x, y):
    xs = np.array(x)
    ys_orig = np.array(y)
    ys = np.copy(ys_orig)

    if np.any(xs == ys):
        ys = change_repeated(ys, xs, dim)
        # It cannot be any repeated element
        assert not np.any(xs == ys)
        # It can be change any  algorithm
        assert not np.all(ys == ys_orig)
        # The change must be justify
        assert np.all((ys == ys_orig) | (ys_orig == xs))
        # Check that all values are between [0, dim]
        assert np.all((ys >= 0) & (ys < dim))
#+END_SRC

When it is run with *py.test* the hypothesis library will test the function with
hundreds of random xs and ys, when xs and ys are lists of size *popsize* and the
values between [0, popsize). If it fails, it will show you the /xs/ and /ys/
values for which the code fails the test, it is very useful.

By the way, the original DE can be implemented like:

#+BEGIN_SRC python
    # Init population
    pop = pop_init(popsize, dim, min=min_value, max=max_value)
    fit = np.array([eval(sol) for sol in pop])
    nevals = 0

    while nevals <= maxevals:
        # Generate all random positions
        r1 = np.random.choice(popsize, popsize)
        r2 = np.random.choice(popsize, popsize)
        r3 = np.random.choice(popsize, popsize)
        # Avoid repeated values
        r2 = change_repeated(r2, r1, popsize)
        r3 = change_repeated_list(r3, [r1, r2], popsize)
        # New population, mutation
        V = pop[r1] + F*(pop[r2]-pop[r3])
        # Clipping
        V = np.clip(V, min_value, max_value)
        # Define U
        U = np.copy(pop)
        # Select cr
        cr = np.random.rand(popsize*dim).reshape((popsize, dim))
        # Make sure that for each individual a position is changed
        cr[np.arange(popsize), np.random.choice(dim, popsize)] = 0
        # Eq. 2 (crossover)
        U.flat[cr.flat < CR] = V.flat
        fitU = [eval(sol) for sol in U]
        nevals += popsize
        # Replacement
        better_cond = fitU < fit
        # Expand for dimension
        better_cond = np.repeat(better_cond, dim).reshape((popsize, dim))
        # Replace the best individual in population
        pop = np.where(better_cond, U, pop)
        fit = np.minimum(fit, fitU)
#+END_SRC

I have to organize it a little, but in only 35 lines (including comments) a complete
[[https://en.wikipedia.org/wiki/Differential_evolution][Differential Evolution]] can be implemented. Numpy is awesome!



** DONE Introduction to Julia                       :@computer_science:julia:
   CLOSED: [2020-01-20 Mon 19:19]
   :PROPERTIES:
   :EXPORT_FILE_NAME: julia_intro
   :EXPORT_DATE: 2020-01
   :END:

The last year I have been working in a promising programming language,
[Julia](http://julialang.org/).

Even I have done a presentation focused on people with Computer Science
background (so the talk compares Julia against Python),

[[https://github.com/dmolina/julia_presentacion/raw/master/Julia_Presentation_slides.pdf][Talk in English]]
[[file:/img/julia_intro_en.png]]

Also it was given in Spanish

[[https://github.com/dmolina/julia_presentacion/blob/master/Julia_Presentacion_slides.pdf][Julia Talk in Spanish]]
[[file:/img/julia_intro_es.png]]

The resources of that talk are available at [Github
Repository](https://github.com/dmolina/julia_presentacion/).

* Emacs                                                              :@emacs:

** DONE Elfeed: Using emacs for reading RSS                           :emacs:
   CLOSED: [2017-12-19 Tue 17:52]
   :PROPERTIES:
   :EXPORT_FILE_NAME: emacs_rss
   :ID:       e208e2ea-28e5-4828-9042-a2d48542d3b3
   :END:

In last years I have been using Emacs for almost all my daily tasks:

- Reading my emails (using [[http://www.djcbsoftware.nl/code/mu/mu4e.html][mu4e]]).
- Creating the slides for my courses using org-beamer.
- Using dired to navigate for the file system).
- Publishing this blog (using [[https://gohugo.io/][Hugo]] and [[https://ox-hugo.scripter.co][ox-hugo]]).

The last thing to integrate into emacs is reading blogs and news from RSS files.
Adding [[https://github.com/skeeto/elfeed][elfeed]] and [[https://github.com/remyhonig/elfeed-org][elfeed-org]] I was able to create RSS. elfeed-org
is very simple, it allows to add the feeds as items in org-mode:

#+BEGIN_EXAMPLE
- Blogs                                                              :elfeed:

  - https://www.meneame.net/rss                                  :news:portada:
  - https://www.meneame.net/rss?status=queued                            :news:
  - http://planet.emacsen.org/atom.xml                                :emacs:
  - https://www.reddit.com/r/programming/.rss                     :programming:
  ...
#+END_EXAMPLE

The tags for each feed will be shared for all articles.

Then, loading *elfeed*, it can be obtained a screen showing the different articles:

[[/screen/elfeed.png]]

And selecting an article, it can be open, read and open each link by the default browser.

[[/screen/elfeed2.png]]

Several opinions about elfeed:

- It is very simple to use.

- The use of tags is very powerful, not only they received the tags from the
  category, and you can add a tag to an article.

- The search filter is simple and very powerful, you can filter both for date and for tags.

- The search filter can be kept as bookmark, so using C-x r b it can be seen the
  article using a particular filter.

To summary, *elfeed* has been a great discovery. If you use emacs, give it a try.

** DONE Fill-more or the important of reading documentation     :emacs:trick:
   CLOSED: [2017-12-15 Fri 11:28]
   :PROPERTIES:
   :EXPORT_FILE_NAME: emacs_justify
   :END:

I *love* Emacs and the auto-fill more. When I work I use it always to make
easier to read the text (with a small value, like 80 or 100). Then, if I have
to copy to a Word Document (in collaboration with other people) or a text (like
in the submission of a review) I simple set the fill-column to a large value
(2000 or similar), with C-x f. Later, I copy all the text.

Until now I have suffered in silence a small problem in text-mode (not in
org-mode). If you put

#+BEGIN_SRC sh
Text.

- Item 1.
- Item 2.
#+END_SRC

After the fill-mode, you have:

#+BEGIN_SRC sh
Text.

- Item 1 Item 2.
#+END_SRC

And to have in right you have to put a line between them:

#+BEGIN_SRC sh
Text.

- Item 1.

- Item 2.
#+END_SRC

(The line between Text and first item is also required).

I though it was something inevitable, but checking the documentation,

https://www.emacswiki.org/emacs/FillParagraph

I have known that with a simple line in elisp that behavior is fixed:

#+BEGIN_SRC elisp
    ;; The original value is "\f\\|[      ]*$", so we add the bullets (-), (+), and (*).
    ;; There is no need for "^" as the regexp is matched at the beginning of line.
    (setq paragraph-start "\f\\|[ \t]*$\\|[ \t]*[-+*] ")
#+END_SRC

I must check the available documentation more often :-).

* Teaching                                           :@teaching:@programming:

** DONE Using Python for Business Intelligence              :python:teaching:
   CLOSED: [2017-10-09 Mon 18:18]
   :PROPERTIES:
   :EXPORT_FILE_NAME: python_bi
   :EXPORT_DATE: 2017-10-09
   :EXPORT_HUGO_TAGS: teaching python
   :END:

Two weeks ago I started my first teaching day, replacing a teacher that has
still not gone to Ceuta (because the temporal contract was offered to many
people, and all of them refuse it). Do not worry, they will have the material, I
said to myself, naïvely.

However, my Phd. advisor, the coordinator of the course, has decided to replace
the practice classes from [[https://www.knime.com/][Knime]] to Python using the different tools availables.
The reason? Because the Python, with R, are very popular in [[https://en.wikipedia.org/wiki/Data_science][Data Science]]. Also,
in Python there are very good tools for data analysis (like [[http://www.numpy.org/][numpy]], [[http://pandas.pydata.org/][pandas]]) or
machine learning ([[http://scikit-learn.org/stable/][scikit-learn]], ...). It seems a good idea, but I have not
material, and I have only two days :-O.

Even more, I had still no access to the Moodle for the material of the course.
So, after a very busy Saturday, I finished including a material,  in
http://github.com/dmolina/es_intro_python, with interesting references and an
install introduction.

Also, I use a very curious tool, https://gitpitch.com, that allow to create
slides from a markdown file from the repository github, [[https://gitpitch.com/dmolina/es_intro_python/master?grs=github&t=moon][Slides using Pitch]].

My final experience was:

- Very few students, so it was very relaxed because you can solve the problems
  for each student. However, using the [[https://www.anaconda.com/][anaconda]] there is few problems (and the .
  In prevision of the big size of the anaconda distribution, my downloaded
  version was copied by USB Disk to students.

- The [[http://jupyter.org/][jupyter notebook]] allow to test the python code without installing or
  learning an IDE (later they can install which they prefer, but for teaching
  you do not need any of them).

- You have to prepare exercises, because if not, you talk and show and you can
  finished in few minutes a material that takes you many hours.

- When you have only a weekend for preparing material, I must have already strong
  knowledge about the topic (fortunately,  it was my case). If not, you will not
  be confident teaching it.

For the second day, I was preparing another slide for teaching pandas (with the
most useful operations, by my experience), available as pdf format here:
[slides_pandas.pdf](./slides/slides_pandas.pdf) (In a future post, I will say as I
prepare my slides using Emacs+Org-mode). /Unfortunately/, the new teacher was
ready,  and I have to finish my courses using python for BI.

** DONE Introduction to CMake
   CLOSED: [2018-11-24 Sat 22:11]
   :PROPERTIES:
   :EXPORT_FILE_NAME: intro_cmake
   :EXPORT_DATE: 2018-11-24
   :EXPORT_HUGO_TAGS: cmake cpp teaching
   :END:

In my last course, I decided to give a small introduction about CMake. The
reason is that, although we teach them Make, the majority of students do not use
them in their programs. In fact, many times they create a "makefile" program to
pretend they are using "make", but actually, it is a bash script.
My intention is to teach them [[http://cmake.org/][*Cmake*]] to encourage them to use an automatic tool
for compiling, expecting they use it more, by its simpler syntax.

The english version is:

[[http://htmlpreview.github.io/?https://github.com/dmolina/intro_cmake/blob/master/cmake_en.html][file:/img/capture_english.png]]

The spanish version is:

[[http://htmlpreview.github.io/?https://github.com/dmolina/intro_cmake/blob/master/cmake_es.html][file:/img/capture_spanish.png]]

All the source code (in [[https://github.com/hakimel/reveal.js/][reveal.js]], through [[https://github.com/yjwen/org-reveal/][org-reveal]]) are available at:
https://github.com/dmolina/intro_cmake

** TODO Introducción a CMake
   :PROPERTIES:
   :EXPORT_FILE_NAME: intro_cmake.es
   :EXPORT_DATE: 2018-11-24
   :EXPORT_HUGO_TAGS: cmake cpp teaching
   :END:

En mi último curso, decidí dar una pequeña introducción sobre CMake:


[[http://htmlpreview.github.io/?https://github.com/dmolina/intro_cmake/blob/master/cmake_es.html][file:/img/capture_spanish.png]]


* OpenSource                                                    :@opensource:

** DONE Firefox 3.5 and Mouseless              :firefox:opensource:mouseless:
   CLOSED: <2017-12-05 Tue 12:10>
   :PROPERTIES:
   :EXPORT_FILE_NAME: firefox35
   :END:

I have recently changed to [[https://www.mozilla.org/en-US/firefox/new/][Firefox 3.5]], and it is awesome!!

The main improvements I have checked:

- Better performance.

- Reader mode, it is very useful to read without distractions, specially in
  mobile. Also, it is mouseless friendly, with the shortkey *Ctrl+Alt+r*.

- Screenshots of a website, that you can share with anybody (not more excuses
  for my students for not showing me their web app in develop).

The bad thing is that many extensions are not valid anymore:

- [[https://www.zotero.org/][Zotero]] has changed to be a java application, and the great [[https://github.com/vspinu/zotelo][Zotelo (extension
  for Emacs)]] is not working anymore :-(.

- Also, several extensions to improve the mouseless navigation stop working.

Fortunately, /uBlock Origin/ is still working, and I have found [[https://addons.mozilla.org/en-US/firefox/addon/tridactyl-vim/][Tridactyl]], an
extension with several nice features:

- *f* and *F* allows you to open links (in same tab or new) identifying them with
  letters (in a very sensible way, my favourive way until now).

- *b* is bookmarks, it allows you to go to another open tab.

- *s* is search mode using the history, with tab you can go your favourite website
  more easily.

- And *ZZ* close all firefox tabs, very useful for a person with Vim-background
  like me :-).

To summarize, if you do not like use the mouse for almost everything, and you
want to browse more easily, try [[https://addons.mozilla.org/en-US/firefox/addon/tridactyl-vim/][Tridactyl]].

* Computer_Science                                        :@computer_science:

** DONE Participation in IEEE Congress on Evolutionary Computation CEC'2018
   CLOSED: [2018-11-13 Tue 14:09]
   :PROPERTIES:
   :EXPORT_HUGO_TAGS: computer_science
   :EXPORT_FILE_NAME: cec2018
   :END:

Several weeks ago, I was at the the [[http://www.ecomp.poli.br/~wcci2018/][IEEE Conference on Evolutionary Computation
(CEC'2018)]], and also at the National Conference on Artificial Intelligence,
in Spain, [[https://sci2s.ugr.es/caepia18/inicio.html][website]].

In https://speakerdeck.com/dmolina there are the slides of my
presentations in the International Conference.

In particular, my works are the following:

- A new algorithm, *SHADE-ILS* which won the Large Scale Global Optimization,
  [[https://speakerdeck.com/dmolina/shade-with-iterative-local-search-for-large-scale-global-optimization][slides]]. You spanish readers, there is also a new [[https://speakerdeck.com/dmolina/shade-con-una-busqueda-local-iterativa-para-optimizacion-continua-de-alta-dimensionalidad][version in Spanish.]]

*In English*
<script async class="speakerdeck-embed"
data-id="22192a5760234cb8984632450bec1b42" data-ratio="1.33333333333333"
src="//speakerdeck.com/assets/embed.js"></script>

*In Spanish*
<script async class="speakerdeck-embed"
data-id="91646e938fd34096b1613126a1828101" data-ratio="1.33333333333333"
src="//speakerdeck.com/assets/embed.js"></script>

#+caption: Certificate as a winner of the LSGO competition
[[file:/img/winner_lsgo_2018.png]]

- A new website for comparisons algorithms, [[https://tacolab.org]], which is briefly
  described [[https://speakerdeck.com/dmolina/taco-toolkit-for-automatic-comparison-optimizers-for-lsgo][here in English]], and [[http://slides.tacolab.org/][also in Spanish]].

*PS*: I will talk about the Tacolab website in next entries, because it is the
results of many weeks of works.

** DONE New LSGO Competition at the CEC'2019
   CLOSED: [2018-12-13 Thu 11:47]
   :PROPERTIES:
   :EXPORT_HUGO_TAGS: computer_science
   :EXPORT_FILE_NAME: lsgo_cec2019
   :END:

I write because I am organizing the [[http://www.tflsgo.org/special_sessions/cec2019.html][Large-Scale Global Optimization Competition]]
at the [[http://cec2019.org/][IEEE Congress on Evolutionary Computation CEC'2019]], with interesting
news:

- Source code for C++/Matlab/Java/Python.

- The source code store during the run all required files with the results, you
  do not need to worry about that, we do it for you!

- In python it is as simple as /pip install cec2013lsgo/ to be able to run the
  experiments, in C++, and the source code and documentation is [[https://github.com/dmolina/cec2013lsgo/][freely available]].

- The new site [[https://tacolab.org][tacolab.org]] to compare your own proposals with existings ones, it
  do the tables, figures and comparisons for you (including statistical testing).

There is not excuse for not participating!

** DONE Packages in Python for CEC'2019 100 Digit Competition
   CLOSED: [2018-12-14 Fri 12:11]
   :PROPERTIES:
   :EXPORT_HUGO_TAGS: computer_science python
   :EXPORT_FILE_NAME: cec2019comp100digit
   :END:

I usually design my evolutionary algorithms in Python (initially for
prototyping, but I am too lazy for doing later a version in C/C++ or similar).
However, unfortunately, the majority of people in my area work in Matlab :sob:.
Thus, sometimes I have to wrap the source code for the benchmarks in competition
to python :relaxed:.

This is the story of the my new package at PyPi:
[[https://pypi.org/project/cec2019comp100digit/]].

This package is for being able to participate in the [[http://cec2019.org/programs/competitions.html#cec-06][CEC'2019 100-Digit Challenge
Competition]], website here:
http://www.ntu.edu.sg/home/epnsugan/index_files/CEC2019/CEC2019.htm.
That website was the source code in C/C++ and Matlab (using mex), but it was
missing Python. This package solves it.

As usual, the complete source code is [[https://github.com/dmolina/cec2019comp100digit][available at Github]].

In the package Pypi page there is [[https://pypi.org/project/cec2019comp100digit/][more documentation]], but in the following I
briefly describe the API:

The package is very simple to use. There is a package cec2019comp100digit with
three functions:

- *init(fun_id, Dim)*
  Init the function for the dimension selected.

- *eval(sol)*
  Eval the solution, when sol is a numpy (or array) of dimension *Dim*.

- *end()*
  Free resources.

*** Installation

It as simple as:

#+BEGIN_SRC sh
pip install cec2019comp100digit
#+END_SRC

Requirements:

- Python3.
- Numpy.
- Cython.

*** Process

- For init the function.

  #+BEGIN_SRC python
  from cec2019comp100digit import cec2019comp100digit
  bench = cec2019comp100digit
  bench.init(3, 10) # Init function 3 with dimension 10
  #+END_SRC

- To create one or several solutions to eval

  It can be used both numpy and/or array (but only numpy has been actually
  tested).

  #+BEGIN_SRC python
  import numpy as np
  sol = np.random.rand(10)
  #+END_SRC

- Evaluate the solution

  It is as simple as:

  #+BEGIN_SRC python
  fit = bench.eval(sol)
  #+END_SRC

- Finally, for free the resources

  #+BEGIN_SRC python
  bench.end()
  #+END_SRC

You can also use it for participate in the competition.

I would like to take this opportunity to remind you that I too am organising
[[https://dmolina.github.io/en/post/lsgo_cec2019/][another competition]], you do not any excuse :smile:.
